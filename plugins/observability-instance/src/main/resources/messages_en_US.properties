#
# * Copyright (c) GBA-NCTI-ISDC. 2022-2024.
# *
# * openGauss DataKit is licensed under Mulan PSL v2.
# * You can use this software according to the terms and conditions of the Mulan PSL v2.
# * You may obtain a copy of Mulan PSL v2 at:
# *
# * http://license.coscl.org.cn/MulanPSL2
# *
# * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND,
# * EITHER EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT,
# * MERCHANTABILITY OR FITFOR A PARTICULAR PURPOSE.
# * See the Mulan PSL v2 for more details.
# * -------------------------------------------------------------------------
# *
# * messages_en_US.properties
# *
# * IDENTIFICATION
# * plugins/observability-instance/src/main/resources/messages_en_US.properties
# *
# * -------------------------------------------------------------------------
#


"DB.enable_thread_pool.suggestExplain         = Open thread pool function on said.
"DB.log_duration.suggestExplain               = With this option is set to off, log_min_duration_statement differs log_min_duration_statement record query text.
"DB.log_min_duration_statement.suggestExplain = Set to 250, all run time not shorter than 250 ms SQL statements can be recorded.
"DB.log_statement.suggestExplain              = None said not recorded statements.DDL said record all data definition statements, such as CREATE, ALTER, and DROP statement.

"OS.vm.overcommit_memory.suggestExplain = Vm. Overcommit_memory file specifies the kernel for memory allocation strategy, its value is 0, 1, 2

0 = (default) said the kernel will check whether there is enough memory available supply process; If there is enough memory available, memory applications allow; Otherwise, the memory for failure, and the error is returned to the application process. 0 is heuristic overcommitting handle, will try to reduce the use of the swap, the root can be allocated slightly more memory than the average user

1 = the kernel allows allocation of all physical memory, however, the current state of the memory, allowing more than CommitLimit, until run out of memory. On the database server is set to 1, is not recommended to try to avoid using the swap.

2 = said not allowed more than CommitLimit values"

DB.bgwriter_delay.paramDetail             = Set the write the back-end process "dirty" the time interval between the Shared buffer
DB.bgwriter_delay.suggestExplain          = In the larger data write pressure can try to reduce the value in the scene in order to reduce the pressure of the checkpoint
DB.bgwriter_delay.unit                    = ms
DB.pagewriter_thread_num.paramDetail        = Set the backend process
DB.pagewriter_thread_num.unit               = The number of
DB.enable_thread_pool.paramDetail         = The control function of whether to use a thread pool
DB.enable_thread_pool.unit                = Boolean value
DB.log_duration.paramDetail               = Control each completed record of SQL statement execution time. Extended query protocols are used for the client, will record the syntax analysis, binding, and perform the time spent on each step
DB.log_duration.unit                      = Boolean value
DB.log_error_verbosity.paramDetail        = Control server log write the detailed degree of each record
DB.log_error_verbosity.suggestExplain     = Terse represents output does not include the DETAIL, HINT, records of the QUERY and the CONTEXT error message.Verbose output including SQLSTATE error code, source code file name, the function name and the number of rows in the wrong.Default on behalf of output including the DETAIL, HINT, records of the QUERY and the CONTEXT error messages, not including SQLSTATE error code, source code file name, the function name and the number of rows in the wrong
DB.log_error_verbosity.unit               = Enumeration type
DB.log_min_duration_statement.paramDetail = When the duration of a statement is greater than or equal to the specified number of milliseconds, log_min_duration_statement parameter is used to control the record the duration of each complete statement
DB.log_min_duration_statement.unit        = ms
DB.log_min_error_statement.paramDetail    = Control in the SQL server error log.
DB.log_min_error_statement.suggestExplain = \u6709\u6548\u503C\u6709\u8C03\u8BD5\u3001debug5 debug4, debug3, debug2, debug1,\u4FE1\u606F,\u65E5\u5FD7,\u6CE8\u610F,\u8B66\u544A\u3001\u9519\u8BEF,\u81F4\u547D\u7684,\u6050\u614C\u3002
DB.log_min_error_statement.unit           = Enumeration type
DB.log_min_messages.paramDetail           = The message level control to the server log file. Each level contains the information in the row behind it all levels. The lower level, the less the server running log message
DB.log_min_messages.suggestExplain        = \u6709\u6548\u503C\u6709\u8C03\u8BD5\u3001debug5 debug4, debug3, debug2, debug1,\u4FE1\u606F,\u65E5\u5FD7,\u6CE8\u610F,\u8B66\u544A\u3001\u9519\u8BEF,\u81F4\u547D\u7684,\u6050\u614C\u3002
DB.log_min_messages.unit                  = Enumeration type
DB.log_statement.paramDetail              = Control record SQL statements. On extending the query protocols used by the client, record received news events and the value of the binding parameters
DB.log_statement.unit                     = Enumeration type
DB.max_io_capacity.paramDetail            = Set the back-end process batch brush pages per second IO ceiling, need according to specific business scenarios and disk I/o capability set machine
DB.max_io_capacity.unit                   = KB
DB.max_process_memory.paramDetail         = Set up a database node largest physical memory available
DB.max_process_memory.suggestExplain      = Database node on the numerical need according to the system of physical memory and single node deployment master database nodes is decided. Computation formula is as follows: (physical memory size - vm. Min_free_kbytes)  * 0.7 / (1 master node number). The coefficient of the purpose is to guarantee the reliability of the system as much as possible, not caused by database memory expansion node OOM. The formula mentioned in the vm min_free_kbytes, its meaning is reserved operating system memory used by the kernel, is often used as a communication transceiver in the operating system kernel memory allocation, at least for 5 \uFFFD. Namely, max_process_memory = physical memory * 0.665 / (1) master node number
DB.max_process_memory.unit                = Boolean value
DB.pagewriter_sleep.paramDetail           = On the set for incremental checkpoint, pagewrite thread every brush pagewriter_sleep time of a batch of dirty pages footwall. When the proportion of dirty pages occupy shared_buffers reaches dirty_page_percent_max, each batch of pages at a set number of max_io_capacity page to calculate the value of the brush, the rest is less in proportion each batch page number
DB.pagewriter_sleep.unit                  = ms
DB.thread_pool_attr.paramDetail           = Detailed attribute is used to control the function of the thread pool, this parameter can only take effect after enable_thread_pool open.
DB.thread_pool_attr.unit                  = character
DB.track_stmt_retention_time.paramDetail  = Combination of parameters, control the quantity/slow SQL record retention time. Read the parameters for 60 seconds period, and perform the cleaning records of more than retention time, only the sysadmin user can access
DB.track_stmt_retention_time.unit         = character
DB.track_stmt_stat_level.paramDetail      = Control statement execution trace level, the parameters in the first part is not OFF, will record all the SQL, the first part is OFF, the second part is a OFF cases, only records the slow SQL
DB.track_stmt_stat_level.unit             = character
DB.work_mem.paramDetail                   = Job execution judgment may use memory in the footwall operator is influenced by inventory
DB.work_mem.suggestExplain                = Parameter is usually a balance, that is, to ensure the concurrent throughput, and to ensure the Performance of the single query operation, so the need according to the actual implementation (a combination of the Explain output Performance) tuning
DB.work_mem.unit                          = Boolean value

OS.MTU.paramDetail                              = The maximum transmission unit node network card. OS the default value is 1500, adjusted to 8192 can improve the performance of SCTP protocol data transceiver
OS.MTU.unit                                     = byte
OS.kernel.sem.paramDetail                       = The kernel semaphore parameters set size
OS.kernel.sem.unit                              = byte
OS.kernel.shmall.paramDetail                    = The kernel of the available amount of Shared memory
OS.kernel.shmall.unit                           = byte
OS.kernel.shmmax.paramDetail                    = A maximum of the kernel parameters define a single Shared memory segment
OS.kernel.shmmax.unit                           = byte
OS.net.core.netdev_max_backlog.paramDetail      = In the rate of each network interface receives packets faster than the rate of kernel processing these packages, to allow the maximum number of packets sent to queue
OS.net.core.netdev_max_backlog.unit             = The number of
OS.net.core.rmem_default.paramDetail            = The default value of the receiver of the socket buffer size
OS.net.core.rmem_default.suggestExplain         = The default receive window size
OS.net.core.rmem_default.unit                   = byte
OS.net.core.rmem_max.paramDetail                = The maximum number of sockets receiver buffer size
OS.net.core.rmem_max.suggestExplain             = Most TCP data receiving buffer
OS.net.core.rmem_max.unit                       = byte
OS.net.core.somaxconn.paramDetail               = Defines the system of each port's largest listening to the queue length
OS.net.core.somaxconn.suggestExplain            = Used to limit the number of listening (LISTEN) biggest packet queue, more than the number of links will lead to a timeout or trigger retransmission mechanism. Listen in the web application function of backlog will give us the kernel by default parameters of the net. Core. Somaxconn limit to 128, and defined nginx NGX_LISTEN_BACKLOG defaults to 511, it is necessary to adjust this value. On a busy server, increasing the value is helpful to network performance
OS.net.core.somaxconn.unit                      = The number of
OS.net.core.wmem_default.paramDetail            = The default value of socket sender buffer size
OS.net.core.wmem_default.suggestExplain         = The default send window size
OS.net.core.wmem_default.unit                   = byte
OS.net.core.wmem_max.paramDetail                = The maximum number of sockets sender buffer size
OS.net.core.wmem_max.suggestExplain             = Most TCP data buffer
OS.net.core.wmem_max.unit                       = byte
OS.net.ipv4.ip_local_port_range.paramDetail     = Physical machine available temporary port range
OS.net.ipv4.ip_local_port_range.suggestExplain  = Said to outside connection port range, the default is small, this range will also indirectly used for NAT table size
OS.net.ipv4.ip_local_port_range.unit            = The number of
OS.net.ipv4.tcp_fin_timeout.paramDetail         = The system default timeout
OS.net.ipv4.tcp_fin_timeout.suggestExplain      = Disconnect the socket for this end, the TCP remain in a state of FIN - WAIT - 2 time. The other party may be disconnected or has not been end connections or unpredictable process of death
OS.net.ipv4.tcp_fin_timeout.unit                = seconds
OS.net.ipv4.tcp_keepalive_intvl.paramDetail     = When detecting no confirmation, resend detection frequency
OS.net.ipv4.tcp_keepalive_intvl.suggestExplain  = Detecting messages did not get the response, resend the message time interval (in seconds). The default value is 75 seconds. (for general applications, there are some big, this value can change a little according to need. Especially the web server needs to change small the value, 15 is a more appropriate value)
OS.net.ipv4.tcp_keepalive_intvl.unit            = seconds
OS.net.ipv4.tcp_keepalive_probes.paramDetail    = Before that connection failure, send TCP keepalive probe packets. This value multiplied by tcp_keepalive_intvl determines a connection after sending keepalive can have how much time did not respond
OS.net.ipv4.tcp_keepalive_probes.suggestExplain = TCP keepalive probe messages sent time interval (in seconds), is used to confirm a TCP connection is valid
OS.net.ipv4.tcp_keepalive_probes.unit           = seconds
OS.net.ipv4.tcp_keepalive_time.paramDetail      = Said when the keepalive enabled, the frequency of the TCP keepalive messages sent
OS.net.ipv4.tcp_keepalive_time.suggestExplain   = TCP keepalive probe messages sent time interval (in seconds), is used to confirm a TCP connection is valid. But don't send the data to establish the connection on both sides to prevent attacks
OS.net.ipv4.tcp_keepalive_time.unit             = seconds
OS.net.ipv4.tcp_max_syn_backlog.paramDetail     = Records of those who have not yet received the client confirmation of the maximum number of connection requests
OS.net.ipv4.tcp_max_syn_backlog.suggestExplain  = For those who still have not yet received the client confirmation of connection requests, maximum number needs to be saved in the queue. For more than 128 MB of memory system, the default value is 1024, less than 128 MB of 128. If the server is often appear overload, can try to increase the number. Warning! If you see this value is set to greater than 1024, best to modify the include/net/TCP. H TCP_SYNQ_HSIZE inside, to keep TCP_SYNQ_HSIZE * 16 (SYN Flood attack using TCP protocol distribute defects of shaking hands, a false source IP address sends a large number of the TCP SYN - half to open the connection to the target system, eventually leading to the target system Socket queue resources exhausted and can not accept new connections. To cope with this attack, the more widely used in modern Unix systems connected to buffer queue processing way, not to solve this kind of attack, is to use a basic queue processing normal to Connect fully application (the Connect () and the Accept ()), is to use another queue separately store half open the connection. This double queue processing method and some other system kernel measures (such as Syn - Cookies/Caches) joint application, can more effectively relieve small-scale Syn Flood attack (proved)
OS.net.ipv4.tcp_max_syn_backlog.unit            = The number of
OS.net.ipv4.tcp_max_tw_buckets.paramDetail      = Said while keeping the TIME_WAIT state maximum number of TCP/IP connection. If more than the configured value, TIME_WAIT will be immediately released and print the warning message
OS.net.ipv4.tcp_max_tw_buckets.suggestExplain   = System at the same time the largest processing timewait number of sockets. If more than this number, the time to wait the socket will be immediately axe and display warning information. To set the limit, in order to resist those simple pure DoS attacks, however, if the conditions need to be more than the default value of the network, you can improve it (perhaps even more memory). (in fact do NAT best can appropriately increase the value)
OS.net.ipv4.tcp_max_tw_buckets.unit             = The number of
OS.net.ipv4.tcp_retries1.paramDetail            = In the process of building connection TCP maximum retries
OS.net.ipv4.tcp_retries1.suggestExplain         = Give up to respond to a TCP connection request, need to how much time before retrying. The RFC minimum value is 3
OS.net.ipv4.tcp_retries1.unit                   = The number of
OS.net.ipv4.tcp_retries2.paramDetail            = Control the kernel to have establish a connection to the remote host to send data to the number of times
OS.net.ipv4.tcp_retries2.suggestExplain         = Discarding the activation (communication) has been established in TCP connection, need to how much time before retrying. The default value is 15, according to the RTO value to decide, the equivalent of 13-30 minutes (RFC1122 regulation, must be greater than 100 seconds). (this value according to the current network Settings, can be appropriately changed little, I change to 5) within the network
OS.net.ipv4.tcp_retries2.unit                   = The number of
OS.net.ipv4.tcp_rmem.paramDetail                = TCP protocol at the receiving end of the buffer size of available memory
OS.net.ipv4.tcp_rmem.suggestExplain             = Receive tcp_wmem cache Settings
OS.net.ipv4.tcp_rmem.unit                       = byte
OS.net.ipv4.tcp_wmem.paramDetail                = TCP protocol at the writing end of the buffer size of available memory
OS.net.ipv4.tcp_wmem.suggestExplain             =
OS.net.ipv4.tcp_wmem.unit                       = byte
OS.net.ipv4.tcp_wmem.parameterCategory          = network
OS.net.ipv4.tcp_wmem.valueRange                 =
OS.net.ipv4.tcp_sack.paramDetail                = Enable selective response, by selectively response out-of-order packets to improve performance, get to the sender to send only the missing segments (for wide area network) this option should be enabled, but will increase the CPU
OS.net.ipv4.tcp_sack.suggestExplain             = Using Selective ACK, it can be used to find specific lost datagram - so would help to recover quickly. The file said whether to enable Selective response (Selective Acknowledgment), this can be achieved by selectively response out-of-order receives the message to improve performance (this allows the sender to send only the lost packet). (this option should be enabled for wan communication, but it will add to the CPU
OS.net.ipv4.tcp_sack.unit                       = Boolean value
OS.net.ipv4.tcp_syn_retries.paramDetail         = TCP SYN packet retries
OS.net.ipv4.tcp_syn_retries.suggestExplain      = How much for a new connection, the kernel to send a SYN connection request to decide to give up. Should not be greater than 255, the default value is 5, corresponding to the 180 seconds of time.. (for large load and good physical communication network, this value is high, can be changed to 2. This value is only in view of the external connection, the incoming connection, is determined by tcp_retries1)
OS.net.ipv4.tcp_syn_retries.unit                = The number of
OS.net.ipv4.tcp_synack_retries.paramDetail      = TCP SYN response packet maximum retries
OS.net.ipv4.tcp_synack_retries.suggestExplain   = For remote connection requests the SYN, the kernel sends the SYN + ACK datagram, to confirm a SYN connection request packets received. This is called the three-way handshake (threeway handshake) mechanism of the second step. Here decided to sent by the kernel before giving up connection SYN ACK number. Should not be greater than 255, the default value is 5, corresponding to the 180 seconds of time
OS.net.ipv4.tcp_synack_retries.unit             = The number of
OS.net.ipv4.tcp_syncookies.paramDetail          = When there is a SYN waiting queue overflow, enable the cookies, can prevent a small amount of SYN attacks
OS.net.ipv4.tcp_syncookies.suggestExplain       = Only when the kernel compilation occurs when chose CONFIG_SYNCOOKIES role. When there is overflow appeared syn waiting queue syncookies like the other sent. The goal is to prevent the syn flood attack
OS.net.ipv4.tcp_syncookies.unit                 = Boolean value
OS.net.ipv4.tcp_timestamps.paramDetail          = The TCP time stamp (12) will increase in the TCP header, send timeout proportion in a more precise way (see RFC 1323) to enable the RTT calculation, can achieve better performance
OS.net.ipv4.tcp_timestamps.suggestExplain       = Timestamps in other things, can prevent the forgery of sequence number. A 1 g broadband lines may be met with heavy out - of - line numerical old sequence number (if it is due to last time). Timestamp will make it knows this is a 'old packet. Said (the file is enabled in a more accurate than the timeout retransmission method (RFC 1323) to enable the RTT calculation; In order to achieve better performance should enable this option.)
OS.net.ipv4.tcp_timestamps.unit                 = Boolean value
OS.net.ipv4.tcp_tw_recycle.paramDetail          = Said to open a TCP connection in TIME - WAIT state sockets rapid recovery
OS.net.ipv4.tcp_tw_recycle.suggestExplain       = Open the quick TIME - WAIT sockets. Unless technical expert advice or request, please do not modify this value. (do NAT, suggest to open it)
OS.net.ipv4.tcp_tw_recycle.unit                 = Boolean value
OS.net.ipv4.tcp_tw_reuse.paramDetail            = Allow the TIME - WAIT state sockets for a new TCP connection
OS.net.ipv4.tcp_tw_reuse.suggestExplain         = Indicates whether or not allowed to apply in TIME - WAIT state of the socket for the new TCP connection (this to restart some service, quickly and start the prompt after the port is already in use case is helpful)
OS.net.ipv4.tcp_tw_reuse.unit                   = Boolean value
OS.vm.extfrag_threshold.paramDetail             = System memory fails, will the Linux memory fragments score for the current system, if more than the vm extfrag_threshold value, kswapd will trigger the memory compaction. So the value is close to 1000, the system in the processing of memory fragments tend to see the old pages out, for meeting the need of application, and set close to 0, the said system in the processing of memory fragments tend to do the memory compaction
OS.vm.extfrag_threshold.unit                    = score
OS.vm.min_free_kbytes.paramDetail               = Ensure that physical memory has enough free space to prevent sudden change page
OS.vm.min_free_kbytes.unit                      = byte
OS.vm.overcommit_memory.paramDetail             = Control when doing the memory allocation, the kernel checks
OS.vm.overcommit_memory.unit                    = way
OS.vm.overcommit_ratio.paramDetail              = System must not be used too much memory algorithm, the system shall not exceed the memory address space swap RAM the percentage value of this parameter, when the vm. The overcommit_memory = 2 when the parameters take effect
OS.vm.overcommit_ratio.suggestExplain           = The parameter value is only in the vm. Overcommit_memory = 2 cases, this parameter will only take effect

DB.recovery_max_workers.paramDetail = Set the maximum number of parallel playback threads.
DB.recovery_parse_workers.paramDetail = The number of ParseRedoRecord threads in the Extreme RTO feature.
DB.recovery_redo_workers.paramDetail = It is the number of PageRedoWorkers corresponding to each ParseRedoRecord thread in the Ultimate RTO feature.
DB.recovery_min_apply_delay.paramDetail = Set the delay time for backup node playback.
DB.wal_level.paramDetail = Set the level of writing WAL information.
DB.synchronous_commit.paramDetail = Set the synchronization method for the current transaction.
DB.wal_buffers.paramDetail = Set XLOG for storing shared memory space for WAL data_ BLCKSZ number, XLOG_ The default size of BLCKSZ is 8KB.
DB.wal_writer_delay.paramDetail = The write interval of the WalWriter process.
DB.commit_delay.paramDetail = Indicates the time a submitted data has been stored in the WAL buffer.
DB.commit_siblings.paramDetail = When a transaction issues a commit request, if the number of executing transactions in the database is greater than the value of this parameter, the transaction will wait for a period of time (the value of commit_delay), otherwise the transaction will be directly written to the WAL.
DB.wal_flush_timeout.paramDetail = The timeout for traversing WalInsertStatusEntryTbl. The maximum waiting time for WalInsertStatusEntryTbl to traverse the disk IO of Xlog disk brushing adaptive control.
DB.recovery_time_target.paramDetail = Set recovery_ Time_ Target seconds can allow the standby machine to complete log writing and playback.
DB.wal_flush_delay.paramDetail = Encountered WAL while traversing WalInsertStatusEntryTbl_ NOT_ The time interval to wait when entering the COPIED state.

DB.recovery_max_workers.unit = The number of
DB.recovery_parse_workers.unit = The number of
DB.recovery_redo_workers.unit = The number of
DB.recovery_min_apply_delay.unit = ms
DB.wal_level.unit = enumeration Type
DB.synchronous_commit.unit = enumeration Type
DB.wal_buffers.unit = kb
DB.wal_writer_delay.unit = ms
DB.commit_delay.unit = microsecond
DB.commit_siblings.unit = The number of
DB.wal_flush_timeout.unit = microsecond
DB.recovery_time_target.unit = s
DB.wal_flush_delay.unit = microsecond

DB.recovery_max_workers.parameterCategory = log playback
DB.recovery_parse_workers.parameterCategory = log playback
DB.recovery_redo_workers.parameterCategory = log playback
DB.recovery_min_apply_delay.parameterCategory = log playback
DB.wal_level.parameterCategory = set up
DB.synchronous_commit.parameterCategory = set up
DB.wal_buffers.parameterCategory = set up
DB.wal_writer_delay.parameterCategory = set up
DB.commit_delay.parameterCategory = set up
DB.commit_siblings.parameterCategory = set up
DB.wal_flush_timeout.parameterCategory = set up
DB.recovery_time_target.parameterCategory = log playback
DB.wal_flush_delay.parameterCategory = set up

DB.recovery_max_workers.valueRange = integer\uFF0C0~20
DB.recovery_parse_workers.valueRange = integer\uFF0C1~16 \nRecovery can only be set when Extreme RTO is enabled_ Parse_ Workers is>1. Need to cooperate with recovery_ Redo_ Workers use. If recovery is enabled simultaneously_ Parse_ Workers and recovery_ Max_ Workers to enable the recovery of Ultimate RTO_ Parse_ Workers shall prevail, and the parallel playback feature shall be invalidated. Due to the fact that Extreme RTO does not support hot standby mode and master-slave mode, only the parameter hot_ Set standby to off, replication_ When type is set to 1, recovery can be set_ Parse_ Workers is>1. In addition, Extreme RTO does not support columnar storage. In systems that already use or are about to use columnar storage, please turn off Extreme RTO. Due to the built-in flow control of the Extreme RTO, when both the Extreme RTO and the flow control are activated, the Extreme RTO will take priority, making the flow control ineffective during operation.
DB.recovery_redo_workers.valueRange = integer\uFF0C1~8 \nNeed to cooperate with recovery_ Parse_ Workers use. In cooperation with recovery_ Parse_ When using workers, only recovery is available_ Parse_ Workers greater than 1, recovery_ Redo_ The workers parameter only takes effect.
DB.recovery_min_apply_delay.valueRange = integer\uFF0C0~INT_MAX\uFF0CUnit in milliseconds\u3002
DB.wal_level.valueRange = enumeration type\n minimal \nAdvantages: Some important operations (including table creation, index creation, cluster operation, and table replication) can be safely skipped, which can make the operation faster. \nDisadvantage: WAL only provides the basic information needed to recover from a database server crash or emergency shutdown state, and cannot be used to archive logs for data recovery. \n archive \n This parameter increases the log information required for WAL archiving, thereby supporting database archive recovery. \n hot_ Standby \n This parameter further increases the information of SQL queries running on the standby machine, and can only take effect after the database service is restarted. \n In order to enable read-only queries on the standby machine, wal_ Level must be set to hot on the host_ Standby, and the standby machine must have hot turned on_ The standby parameter. Hot_ There is only a slight difference in performance between the standby and archive levels. If their settings have a significant impact on product performance, please feel free to provide feedback. \n logical \n This parameter indicates that WAL logs support logical replication.
DB.synchronous_commit.valueRange = enumeration type\n on\uFF1AIndicates that the host transaction submission needs to wait for the backup machine to flush the corresponding logs to disk. \n off: Indicates that the host transaction submission does not require waiting for the host to flush the corresponding logs to disk, commonly known as asynchronous submission. \n local: indicates that the host transaction submission needs to wait for the host itself to flush the corresponding logs to disk, usually also known as local submission. \n remote_ Write: Indicates that the host transaction submission needs to wait for the backup machine to write the corresponding logs to the file system (without flushing to disk). \n remote_ Receive: Indicates that the host transaction submission needs to wait for the standby machine to receive the corresponding log data (without writing to the file system). \n remote_ Apply: indicates that the host transaction submission needs to wait for the backup machine to complete the playback operation of the corresponding log. \n true: Same as on. \n false: Same as off. \n yes: Same as on. \n no: Same as off. \n 1: Same as on. \n 0: Same as off. \n 2: Same as remote_ Apply.
DB.wal_buffers.valueRange = -1~218\nIf set to -1, it means wal_ The size of buffers varies with the parameter shared_ Buffers automatically adjust to shared_ 1/32 of the buffers, in which case the minimum value is 8 XLOGs_ BLCKSZ, max 2048 XLOGs_ BLCKSZ, when the automatically adjusted value is less than the minimum value, it will be adjusted to the minimum value, and when it is greater than the maximum value, it will be adjusted to the maximum value. \n If is set to another value, it will be set to 4 by default when it is less than 4.
DB.wal_writer_delay.valueRange = integer\uFF0C 1\uFF5E10000\uFF0CUnit in milliseconds\u3002
DB.commit_delay.valueRange = integer\uFF0C 0\uFF5E100000\uFF0CThe unit is microseconds, where 0 represents no delay.
DB.commit_siblings.valueRange = integer\uFF0C 0\uFF5E1000
DB.wal_flush_timeout.valueRange = integer\uFF0C 0 ~ 90000000\uFF08microsecond\uFF09
DB.recovery_time_target.valueRange = integer\uFF0C0~3600\uFF08s\uFF09\n0 means that log flow control is not enabled, while 1-3600 means that the backup machine can recover_ Time_ Completing the writing and playback of logs within the target time ensures that recovery can be performed during the switch between the host and backup machines_ Time_ Target seconds to complete log writing and playback, ensuring that the backup machine can quickly upgrade to the host. Recovery_ Time_ If the target setting time is too small, it will affect the performance of the host, and if set too much, it will lose the flow control effect. In addition, due to the built-in flow control of the Extreme RTO, when both the Extreme RTO and the flow control are activated, the Extreme RTO will take priority, making the flow control ineffective during operation.
DB.wal_flush_delay.valueRange = integer\uFF0C 0 ~ 90000000\uFF08microsecond\uFF09

DB.recovery_max_workers.suggestExplain = The default setting for the installation tool is 4 for better performance
DB.recovery_parse_workers.suggestExplain = Recovery can only be set when Extreme RTO is enabled_ Parse_ Workers is>1. Need to cooperate with recovery_ Redo_ Workers use. If recovery is enabled simultaneously_ Parse_ Workers and recovery_ Max_ Workers to enable the recovery of Ultimate RTO_ Parse_ Workers shall prevail, and the parallel playback feature shall be invalidated. Due to the fact that Extreme RTO does not support hot standby mode and master-slave mode, only the parameter hot_ Set standby to off, replication_ When type is set to 1, recovery can be set_ Parse_ Workers is>1. In addition, Extreme RTO does not support columnar storage. In systems that already use or are about to use columnar storage, please turn off Extreme RTO. Due to the built-in flow control of the Extreme RTO, when both the Extreme RTO and the flow control are activated, the Extreme RTO will take priority, making the flow control ineffective during operation.
DB.recovery_redo_workers.suggestExplain = Need to cooperate with recovery_ Parse_ Workers use. In cooperation with recovery_ Parse_ When using workers, only recovery is available_ Parse_ Workers greater than 0, recovery_ Redo_ The workers parameter only takes effect.
DB.recovery_min_apply_delay.suggestExplain = The setting of this parameter for the primary node is invalid and must be set on the standby node that needs delay. It is recommended to set it on the asynchronous standby node. If the delay is set on the asynchronous standby node, the RTO time for upgrading to primary will be longer. The delay time is calculated based on the timestamp of the transaction submission on the primary server and the current time on the standby machine, so it is necessary to ensure that the clock of the primary and standby systems is consistent. If the delay time is set too long, it may cause the disk where the XLOG file of the standby machine is located to be full Need to balance and consider disk size to set latency time. Operations without transactions will not be delayed. After the master-slave switch, if the original host needs to delay, this parameter needs to be manually configured again. When synchronous_ Commit is set to remote_ When applying, synchronous replication will be affected by this delay, and each COMMIT will need to wait for the backup machine to replay before returning. Using this feature will also make hot_ Stand by_ The feedback is delayed, which may cause the main server to expand. Be careful when using both together. The host has performed DDL operations that hold an AccessExclusive lock, such as DROP and TRUNCATE operations. During the delayed playback of this record on the standby machine, executing a query operation on the operating object on the standby machine will wait for the lock to be released before returning. MOT tables are not supported.
DB.wal_level.suggestExplain = Minimal Advantages: Some important operations (including table creation, index creation, cluster operations, and table replication) It can be safely skipped, which can make the operation faster. Disadvantage: WAL only provides the basic information needed to recover from a database server crash or emergency shutdown state, and cannot be used to archive logs for data recovery. The archive parameter increases the log information required for WAL archiving, thereby supporting database archive recovery. Hot_ The standby parameter further increases the information of SQL queries running on the standby machine, and can only take effect after the database service is restarted. To enable read-only queries on the standby machine, wal_ Level must be set to hot on the host_ Standby, and the standby machine must have hot turned on_ The standby parameter. Hot_ There is only a slight difference in performance between the standby and archive levels. If their settings have a significant impact on product performance, please feel free to provide feedback. The logical parameter indicates that WAL logs support logical replication.
DB.synchronous_commit.suggestExplain = On: indicates that the host transaction submission needs to wait for the backup machine to flush the corresponding logs to disk. Off: indicates that the host transaction submission does not need to wait for the host machine to flush the corresponding logs to disk, commonly referred to as asynchronous submission. Local: indicates that the host transaction submission needs to wait for the host machine to flush the corresponding logs to disk, usually referred to as local submission. remote_write: indicates that the host transaction submission needs to wait for the backup machine to write the corresponding logs to the file System (no need to refresh to disk). Remote_ Receive: Indicates that the host transaction submission needs to wait for the standby machine to receive the corresponding log data (without writing to the file system). Remote_ Apply: indicates that the host transaction submission needs to wait for the backup machine to complete the playback operation of the corresponding log. True: Same as on. False: Same as off. Yes: Same as on. No: Same as off. 1: Same as on. 0: Same as off. 2: Same as remote_ Apply.
DB.wal_buffers.suggestExplain = If set to -1, it means that the size of wall_buffers is automatically adjusted with the parameter shared_buffers, which is 1/32 of shared_buffers. In this case, the minimum value is 8 XLOG_BLCKSZ and the maximum value is 2048 XLOG_BLCKSZ. The automatically adjusted value is adjusted to the minimum value when it is less than the minimum value, and to the maximum value when it is greater than the maximum value. If set to another value, when it is less than 4, it is set to 4 by default. * When each transaction is committed, the WAL is buffered The content of the flushing area is written to the disk, so setting it to a large value will not bring significant performance improvement. If it is set to a few hundred megabytes, it can improve the performance of writing to disk on servers with many real-time transaction commits. Based on experience, default values can meet most situations.
DB.wal_writer_delay.suggestExplain = 1\uFF5E10000\uFF0CIf the time is too long, it may cause insufficient memory in the WAL buffer. If the time is too short, it can cause the WAL to continuously write, increasing the disk I/O burden.
DB.commit_delay.suggestExplain = 0\uFF5E100000\uFF0CThe unit is microseconds, where 0 represents no delay. When set to a value other than 0, the transaction execution commit will not be immediately written to the WAL, but will still be stored in the WAL buffer, waiting for the WalWriter process to periodically write to the disk. If the system load is high, other transactions may be ready to commit within the delay time. But if there is no transaction ready to commit, this delay is a waste of time.
DB.commit_siblings.suggestExplain =
DB.wal_flush_timeout.suggestExplain = If the time is too long, it may cause a decrease in the frequency of Xlog disk flushing and reduce the processing performance of Xlog.
DB.recovery_time_target.suggestExplain = 0 means that log flow control is not enabled, while 1-3600 means that the backup machine can recover_ Time_ Completing the writing and playback of logs within the target time ensures that recovery can be performed during the switch between the host and backup machines_ Time_ Target seconds to complete log writing and playback, ensuring that the backup machine can quickly upgrade to the host. Recovery_ Time_ If the target setting time is too small, it will affect the performance of the host, and if set too much, it will lose the flow control effect. In addition, due to the built-in flow control of the Extreme RTO, when both the Extreme RTO and the flow control are activated, the Extreme RTO will take priority, making the flow control ineffective during operation.
DB.wal_flush_delay.suggestExplain =

connect.database.tip = Failed to connect to database

exporterinstall.downloadsuccess = The installation package download success
exporterinstall.pkgexists       = Current path under existing installation package, use the installation package to install
exporterinstall.step1           = Initialize the
exporterinstall.step2           = Check the agent environment
exporterinstall.step3           = Check the user information
exporterinstall.step4           = Install agent
exporterinstall.step5           = starting agent
exporterinstall.step6           = Refresh the Prometheus configuration
exporterinstall.step7           = The installation is complete
exporterinstall.uploadsuccess   = Installation completed packet transmission
exporterinstall.repeat.tip1 = Duplicate installations detected:
exporterinstall.repeat.tip2 = Instance {1} has already been collected by exporter({0})
exporterinstall.repeat.tip3 = Installation cannot be continued. Please select a different instance for installation.

exporteruninstall.step1  = Check the Agent environment
exporteruninstall.step10 = Uninstall complete
exporteruninstall.step2  = Stop the Agent
exporteruninstall.step3  = Clear the installed package
exporteruninstall.step4  = Delete the Agent environment
exporteruninstall.step5  = Connection between a host
exporteruninstall.step6  = Find nodeAgent process
exporteruninstall.step7  = Stop nodeAgent
exporteruninstall.step8  = Find opengaussAgent process
exporteruninstall.step9  = Stop opengaussAgent

install.tryAdd = Try to create {0} the user for installation
install.use    = Use {0} user for installation

nodeId.tip = node does not exist

password.tip = root password error

prominstall.downloadsuccess = The installation package download success
prominstall.limit           = Only allowed to install a Prometheus instance
prominstall.pkgexists       = Current path under existing installation package, use the installation package installation is successful
prominstall.promstartfail   = Prometheus boot failure
prominstall.step1           = Start the installation
prominstall.step2           = Check the Prometheus installation environment
prominstall.step3           = Check the user information, connection between a host
prominstall.step4           = Install the Prometheus
prominstall.step5           = Start the Prometheus
prominstall.step6           = Verify the Prometheus startup state
prominstall.step7           = The installation is complete
prominstall.step8           = Uninstall the old Prometheus
prominstall.uploadsuccess   = The installation package transfer success
prominstall.stopServer = Stop Prometheus
prominstall.stopedServer = Stop Prometheus success
prominstall.startServer = Start Prometheus
prominstall.startedServer = Start Prometheus success
prominstall.updatePort = Update Prometheus port
prominstall.updateParam = Update Prometheus configuration parameters
prominstall.clearFolder = Clear install folder


promuninstall.step1 = Check the Prometheus environment
promuninstall.step2 = Stop Prometheus
promuninstall.step3 = clear the installed package
promuninstall.step4 = delete the Prometheus
promuninstall.step5 = Uninstall complete
session.detail.general.message=The session id does not exist, probably the session has finished executing and closed.
session.detail.block.message=The number of rows returned by querying block session through sessionid should be equal to 1, but return {0} 
cluster.state.value.Normal=Normal
cluster.state.value.Unavailable=Unavailable
cluster.state.value.Degraded=Degraded
cluster.state.value.Unknown=Unknown
cluster.node.role.Primary=Primary
cluster.node.role.Standby=Standby
cluster.node.role.Cascade=Cascade
cluster.node.role.Pending=Pending
cluster.node.role.Unknown=Unknown
cluster.node.role.Down=Down
cluster.node.role.Abnormal=Abnormal
cluster.node.role.Manually=Manually stopped
cluster.node.state.Normal=Normal
cluster.node.state.Exception=Exception
cluster.node.state.repair=Need repair
cluster.node.state.Starting=Starting
cluster.node.state.promoting=Wait promoting
cluster.node.state.Promoting=Promoting
cluster.node.state.Demoting=Demoting
cluster.node.state.Building=Building
cluster.node.state.Catchup=Catchup
cluster.node.state.Coredump=Coredump
cluster.node.state.Unknown=Unknown
cluster.node.state.stopped=node stop
cluster.arch={0} primary {1} standby
cluster.state.desc.Normal=All database nodes in the cluster are healthy
cluster.state.desc.Unavailable=The cluster is unavailable
cluster.state.desc.Degraded=The cluster is available, but there are failed database nodes
cluster.state.desc.Unknown=The cluster cannot be connected and the status is unknown
cluster.node.sync.Async=Async
cluster.node.sync.Sync=Sync
cluster.node.sync.Potential=Potential
cluster.node.syncState.Streaming=Streaming
cluster.node.syncState.Catchup=catchup
OS.bin.state.TASK_UNINTERRUPTIBLE=TASK_UNINTERRUPTIBLE
OS.bin.state.TASK_RUNNING=TASK_RUNNING
OS.bin.state.TASK_INTERRUPTIBLE=TASK_INTERRUPTIBLE
OS.bin.state.TASK_STOPPED=TASK_STOPPED
OS.bin.state.TASK_TRACED=TASK_TRACED
OS.bin.state.EXIT_ZOMBIE=EXIT_ZOMBIE
OS.bin.state.EXIT_DEAD=EXIT_DEAD
OS.bin.state.UNKNOWN=unknown
OS.bin.state.STOP=stop

# Tips Exception
tips.exception.getMetricGroupKeyError = Error retrieving metric group key!
tips.exception.noTemplateNodeId = No matching NodeId found!
tips.exception.exporterNotFound = No matching exporter found!
tips.exception.errorTemplateId = No matching template ID found!
tips.exception.agentNotAlive = Failed to connect to the proxy\uFF01
tips.exception.envIdError = Proxy ID error\uFF01

# Metrics group name,name and description
metrics.agent_cpu_seconds_total.name = System CPU and CPU Cores
metrics.agent_cpu_seconds_total.desc = Includes CPU usage and CPU core metrics
metrics.agent_load.name = CPU Average Load
metrics.agent_load.desc = Includes 1m, 5m, 15m CPU average load metrics
metrics.top_db.name = Database Process CPU and Memory Usage
metrics.top_db.desc = Includes database process CPU usage and memory usage
metrics.agent_memory.name = System Memory
metrics.agent_memory.desc = Includes homepage memory metrics
metrics.agent_free.name = System Memory and Swap
metrics.agent_free.desc = Includes memory usage metrics within resource monitoring and swap usage
metrics.agent_network.name = System Network In and Out
metrics.agent_network.desc = Includes network traffic (inbound, outbound) and network card packet loss metrics
metrics.agent_disk.name = Disk IO
metrics.agent_disk.desc = Includes all IO-related metrics
metrics.db_filesystem.name=Database related disk usage rate
metrics.db_filesystem.desc=Includes used capacity, remaining capacity, and total capacity indicators for database related disks
metrics.db_dir_filesystem.name=Database directory related disk usage rate
metrics.db_dir_filesystem.desc=Includes disk space usage metrics for database data directory and x'log directory
metrics.agent_network_socket.name = System Network Socket Count
metrics.agent_network_socket.desc = Includes TCP and UDP socket count metrics
metrics.agent_sockstat.name = System Network Socket Statistics
metrics.agent_sockstat.desc = Includes TCP socket count for system network sockets
metrics.agent_netstat.name = System Network Socket Packet Statistics
metrics.agent_netstat.desc = Includes packet statistics for system network sockets

metrics.local_threadpool_status.name = Database Thread Pool Usage
metrics.local_threadpool_status.desc = Includes database thread pool usage metrics for SQL diagnosis
metrics.gauss_thread_wait_status.name = Active Session Count in Database
metrics.gauss_thread_wait_status.desc = Includes active session count metrics
metrics.pg_stat_database.name = Database TPS
metrics.pg_stat_database.desc = Includes transaction rollback count, transaction commit count, and total count metrics
metrics.gauss_workload_sql_count.name = Database QPS
metrics.gauss_workload_sql_count.desc = Includes database QPS metrics
metrics.gauss_statement_responsetime_percentile.name = Database Response Time for P80 and P95
metrics.gauss_statement_responsetime_percentile.desc = Includes database P80 and P95 metrics
metrics.pg_stat_activity.name = Database Connection Count
metrics.pg_stat_activity.desc = Includes metrics for idle, active, and current database connections
metrics.pg_connections.name = Database Connection Count Statistics
metrics.pg_connections.desc = Includes metrics for used connections and maximum connections in the database
metrics.pg_stat_activity_slow.name = Slow SQL in Database
metrics.pg_stat_activity_slow.desc = Includes metrics for slow SQL queries (greater than 3 seconds)
metrics.pg_wal_write_total.name = Total Database WAL Log Write Data
metrics.pg_wal_write_total.desc = Includes metrics for the total amount of data written to the WAL logs
metrics.pg_wal_send_pressure.name = Database WAL Log Send Pressure
metrics.pg_wal_send_pressure.desc = Includes metrics for the difference in data volume between the current write location and the send location of the WAL logs
metrics.pg_wal_delay.name = Database WAL Log Receive Delay
metrics.pg_wal_delay.desc = Includes metrics for WAL receive, write, and replay delays in the database
metrics.agent_vmstat.name = System Memory Swap In and Out
metrics.agent_vmstat.desc = Includes metrics for memory swap in and out, used for alert monitoring
metrics.agent_filesystem.name = System Disk Usage
metrics.agent_filesystem.desc = Includes metrics related to disk usage, used for alert monitoring
metrics.pg_db_status.name = Database Status
metrics.pg_db_status.desc = Includes metrics for the database's health status, used for alert monitoring
metrics.pg_state_activity_group.name = Database Blocked Session Count
metrics.pg_state_activity_group.desc = Includes metrics for the number of blocked sessions in the database, used for alert monitoring
metrics.pg_tablespace.name = Database Tablespace Capacity
metrics.pg_tablespace.desc = Includes metrics for tablespace capacity, used for alert monitoring
metrics.pg_active_slowsql.name = Database Slow SQL Execution Time
metrics.pg_active_slowsql.desc = Includes metrics for slow SQL query execution time, used for alert monitoring
metrics.pg_lock.name = Database Lock Count
metrics.pg_lock.desc = Includes metrics for lock count, used for alert monitoring
metrics.pg_lock_detail.name = Database Lock Time
metrics.pg_lock_detail.desc = Includes metrics for lock time, used for alert monitoring
metrics.pg_replication_slots.name = Database Primary Replication Slot Delay
metrics.pg_replication_slots.desc = Includes metrics for the delay size of the primary replication slots in the database, used for alert monitoring
metrics.pg_stat_bgwriter.name = Database Dirty Block Cleanup Count
metrics.pg_stat_bgwriter.desc = Includes metrics for the cleanup count of checkpoint, buffer, and backend dirty blocks
metrics.pg_thread_lock.name = Database lock thread
metrics.pg_thread_lock.desc = Includes lock blocking time metrics for alert monitoring
metrics.pg_stat_activity_transaction.name = session transaction
metrics.pg_stat_activity_transaction.desc = includes session transaction duration metrics for alert monitoring
metrics.pg_prepared_xacts.name = 2PC transaction
metrics.pg_prepared_xacts.desc = Includes 2PC transaction duration metrics for alert monitoring
metrics.db_session_memory.name = Large transaction
metrics.db_session_memory.desc = Metrics for large transactions, used for alert monitoring
metrics.pg_stat_replication_xlog.name = Primary/Standby xlog
metrics.pg_stat_replication_xlog.desc = Includes primary/standby xlog difference metrics for alert monitoring
metrics.db_sql.name = Database SQL overview
metrics.db_sql.desc = Includes metrics for database query count, insert count, update count, delete count, etc., used\
  \ for alert monitoring
metrics.agent_host_conn_status.name = Host availability
metrics.agent_host_conn_status.desc = Host availability metrics for monitoring
cluster.node.log.switchover.reason.switchover=Manually switch the primary node
cluster.node.log.switchover.reason.failover=The primary node is automatically switched over when it is down
cluster.node.syncState.Delay=delay
cluster.node.syncState.Unknown=unknown